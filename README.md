# Training Lunar Lander RL agents

Employing 2 classes of algorithms (DQN and PPO) in training RL agents to solve a classic rocket trajectory optimization problem [Lunar Lander](https://gymnasium.farama.org/environments/box2d/lunar_lander/). Within each family, variants of the algorithms are implemented.


Please refer to the README.md in the 2 subfolders for installation and execution of the relevant algorithms.

*Comparison between Prioritized Dueling DDQN and PPO:*
![epoch_PPO_vs_DQN_vs_Random](https://github.com/ericdong314/rl-lunar-lander/assets/56725529/cbff2783-7122-45ba-8abf-4e1fbc11a89f)


*DQN agents:*
<p align="middle">
<img src="https://github.com/ericdong314/rl-lunar-lander/assets/56725529/e252a7d6-2243-4008-8753-d7a6bcd241a7" width="49%" />
<img src="https://github.com/ericdong314/rl-lunar-lander/assets/56725529/e5a01dfc-5a27-4605-af6d-29a5cb87f095" width="49%" />
</p>

*PPO Agents:*

<p align="middle">
<img src="https://github.com/ericdong314/rl-lunar-lander/assets/56725529/5710bf74-edda-424b-a469-920a41a7fb12" width="49.5%"/>
<img src="https://github.com/ericdong314/rl-lunar-lander/assets/56725529/2368405e-4d50-4678-b430-3753186f48d5" width="48.5%"/>
</p>



Watch the following video to see the performance of the agents:

https://github.com/ericdong314/rl-lunar-lander/assets/56725529/02011adf-590a-40a8-881b-95c6e7f999ec


(Credit to @jeffyfung for PPO implementation; Video recorded by Henry Liu)

